<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Cricket on Datasheet for Game Commentary Datasets</title><link>https://ZzZqr.github.io/AIGGC-datasheet/tags/cricket/</link><description>Recent content in Cricket on Datasheet for Game Commentary Datasets</description><generator>Hugo -- 0.147.2</generator><language>en-us</language><atom:link href="https://ZzZqr.github.io/AIGGC-datasheet/tags/cricket/index.xml" rel="self" type="application/rss+xml"/><item><title>A Hybrid Deep Learning Model for Automated Cricket Commentary Generation</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/</guid><description>&lt;p>The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model.&lt;/p></description></item><item><title>Automated cricket commentary generation using deep learning</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/automated-cricket-commentary-generation-using-deep-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/automated-cricket-commentary-generation-using-deep-learning/</guid><description>&lt;p>This work presents an automated and novel system for cricket commentary generation by the introduction of event driven approach and image captioning features. The presented system uses artificial intelligence and machine learning (ML) based methods to investigate real-time match data and generate real-time commentary by Image Captioning technique. For this purpose, deep neural network-based models and digital image processing techniques are used to detect the significant moments in the real-time match and generate commentary based on these real-time match events. The proposed method has been assessed using a dataset of 2 hours live cricket matches of India and England. After processing the match video, it has been observed that the developed model is successfully able to generate high-quality real-time commentary with a significant amount of accuracy. By commissioning leading-edge deep neural network-based model, the developed model determines the fitness to generate subtitles that are not only precise but also contextually appropriate, and efficiently apprehending the essence of the input frames.&lt;/p></description></item><item><title>Ball-by-Ball Cricket Commentary Generation using Stateful Sequence-to-Sequence Model</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/ball-by-ball-cricket-commentary-generation-using-stateful-sequence-to-sequence-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/ball-by-ball-cricket-commentary-generation-using-stateful-sequence-to-sequence-model/</guid><description>&lt;p>Due to the availability of high performance computational devices and enormous video data, deep learning algorithms are assisting for human understandable description of videos. Automatic commentary generation of cricket videos take advantage of aforementioned intelligent techniques. VGG-16 network facilitates extraction of visual pattern from frames followed by encoder-decoder LSTM model. Proposed model can handle variable length input data to output variable number of sequential output. Moreover, the model has ability to encompass temporal information to predict the line and length bowled by bowler, the shot selection of batsman and outcome of the ball. Due to unavailability of cricket commentary dataset, a novel cricket commentary dataset containing video-commentary pairs is presented. Evaluation is also performed on benchmark video captioning datasets which are Microsoft Video Description Dataset (MSVD) and MSR - Video to Text dataset (MSRVTT). Captions generated by our model are evaluated on video captioning metrics which are METEOR, BLEU, ROGUE L and CIDEr and outperforms the baseline model.&lt;/p></description></item><item><title>Outcome Classification in Cricket Using Deep Learning</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/outcome-classification-in-cricket-using-deep-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/outcome-classification-in-cricket-using-deep-learning/</guid><description>&lt;p>With the growth in applications of Artificial Intelligence day by day, every domain is going automated. Machine learning has enabled systems to learn the process on its own in order to reduce the human labour. In sports like cricket, Football AI has not been used on a greater scale but there are certain areas where it can be of great help to apply AI techniques. In this paper the outcome classification task has been performed on cricket videos. The main purpose of performing such activities is to create automatic commentary generation. There are many sub-tasks needed to be considered for this task. One of those tasks is to classify the outcome of each ball for which commentary is to be generated. There has not been any standard data to perform such task, neither are any benchmark results to compare a new one. So in this paper, from data collection to performing the classification operation with results has been produced. There are four most general outcomes in the game of cricket such as Run, Dot, Boundary, Wicket. With the help of Convolutional Neural Network and Long Short-Term Memory Networks the outcome of cricket match ball by ball videos has been classified with 70% of test accuracy.&lt;/p></description></item><item><title>Story Selection and Recommendation System for Colour Commentary in Cricket</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/story-selection-and-recommendation-system-for-colour-commentary-in-cricket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/story-selection-and-recommendation-system-for-colour-commentary-in-cricket/</guid><description>&lt;p>During a cricket match, commentary keeps the viewers entertained and updated about the game. Quoting relevant stories related to the current game scenario makes the game more interesting. But the knowledge of commentator, however vast for a human being, is still limited relative to the total set of available stories. A major challenge is to narrate the most relevant stories (past incidents) based on the current (never-before-seen) game state. The paper proposes a solution which is an AI based approach that will assist the colour commentators in effective storytelling that is interesting to the audience, and related to what is actually happening in the game being broadcast.&lt;/p></description></item></channel></rss>