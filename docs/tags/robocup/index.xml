<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Robocup on Datasheet for Game Commentary Datasets</title><link>https://ZzZqr.github.io/AIGGC-datasheet/tags/robocup/</link><description>Recent content in Robocup on Datasheet for Game Commentary Datasets</description><generator>Hugo -- 0.147.2</generator><language>en-us</language><atom:link href="https://ZzZqr.github.io/AIGGC-datasheet/tags/robocup/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning to sportscast: a test of grounded language acquisition</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-to-sportscast-a-test-of-grounded-language-acquisition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-to-sportscast-a-test-of-grounded-language-acquisition/</guid><description>&lt;p>We present a novel commentator system that learns language from sportscasts of simulated soccer games. The system learns to parse and generate commentaries without any engineered knowledge about the English language. Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games. The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model. We also present a novel algorithm, Iterative Generation Strategy Learning (IGSL), for deciding which events to comment on. Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries.&lt;/p></description></item><item><title>Training a Multilingual Sportscaster: Using Perceptual Context to Learn Language</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/training-a-multilingual-sportscaster-using-perceptual-context-to-learn-language/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/training-a-multilingual-sportscaster-using-perceptual-context-to-learn-language/</guid><description>&lt;p>We present a novel framework for learning to interpret and generate language using only perceptual context as supervision. We demonstrate its capabilities by developing a system that learns to sportscast simulated robot soccer games in both English and Korean without any language-specific prior knowledge. Training employs only ambiguous supervision consisting of a stream of descriptive textual comments and a sequence of events extracted from the simulation trace. The system simultaneously establishes correspondences between individual comments and the events that they describe while building a translation model that supports both parsing and generation. We also present a novel algorithm for learning which events are worth describing. Human evaluations of the generated commentaries indicate they are of reasonable quality and in some cases even on par with those produced by humans for our limited domain.&lt;/p></description></item></channel></rss>