<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Board on Datasheet for Game Commentary Datasets</title><link>https://ZzZqr.github.io/AIGGC-datasheet/tags/board/</link><description>Recent content in Board on Datasheet for Game Commentary Datasets</description><generator>Hugo -- 0.147.2</generator><language>en-us</language><atom:link href="https://ZzZqr.github.io/AIGGC-datasheet/tags/board/index.xml" rel="self" type="application/rss+xml"/><item><title>A Japanese Chess Commentary Corpus</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-japanese-chess-commentary-corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-japanese-chess-commentary-corpus/</guid><description>&lt;p>In recent years there has been a surge of interest in the natural language prosessing related to the real world, such as symbol grounding, language generation, and nonlinguistic data search by natural language queries. In order to concentrate on language ambiguities, we propose to use a well-defined {\textquotedblleft}real world,{\textquotedblright} that is game states. We built a corpus consisting of pairs of sentences and a game state. The game we focus on is shogi (Japanese chess). We collected 742,286 commentary sentences in Japanese. They are spontaneously generated contrary to natural language annotations in many image datasets provided by human workers on Amazon Mechanical Turk. We defined domain specific named entities and we segmented 2,508 sentences into words manually and annotated each word with a named entity tag. We describe a detailed definition of named entities and show some statistics of our game commentary corpus. We also show the results of the experiments of word segmentation and named entity recognition. The accuracies are as high as those on general domain texts indicating that we are ready to tackle various new problems related to the real world.&lt;/p></description></item><item><title>Annotating Event Appearance for Japanese Chess Commentary Corpus</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/annotating-event-appearance-for-japanese-chess-commentary-corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/annotating-event-appearance-for-japanese-chess-commentary-corpus/</guid><description>&lt;p>In recent years, there has been a surge of interest in natural language processing related to the real world, such as symbol grounding, language generation, and non-linguistic data search by natural language queries. Researchers usually collect pairs of text and non-text data for research. However, the text and non-text data are not always a {\textquotedblleft}true{\textquotedblright} pair. We focused on the shogi (Japanese chess) commentaries, which are accompanied by game states as a well-defined {\textquotedblleft}real world{\textquotedblright}. For analyzing and processing texts accurately, considering only the given states is insufficient, and we must consider the relationship between texts and the real world. In this paper, we propose {\textquotedblleft}Event Appearance{\textquotedblright} labels that show the relationship between events mentioned in texts and those happening in the real world. Our event appearance label set consists of temporal relation, appearance probability, and evidence of the event. Statistics of the annotated corpus and the experimental result show that there exists temporal relation which skillful annotators realize in common. However, it is hard to predict the relationship only by considering the given states.&lt;/p></description></item><item><title>Annotating Modality Expressions and Event Factuality for a{Japanese Chess Commentary Corpus</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/annotating-modality-expressions-and-event-factuality-for-a-japanese-chess-commentary-corpus/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/annotating-modality-expressions-and-event-factuality-for-a-japanese-chess-commentary-corpus/</guid><description>&lt;p>In recent years, there has been a surge of interest in the natural language processing related to the real world, such as symbol grounding, language generation, and nonlinguistic data search by natural language queries. We argue that shogi (Japanese chess) commentaries, which are accompanied by game states, are an interesting testbed for these tasks. A commentator refers not only to the current board state but to past and future moves, and yet such references can be grounded in the game tree, possibly with the help of modern game-tree search algorithms. For this reason, we previously collected shogi commentaries together with board states and have been developing a game commentary generator. In this paper, we augment the corpus with manual annotation of modality expressions and event factuality. The annotated corpus includes 1,622 modality expressions, 5,014 event class tags and 3,092 factuality tags. It can be used to train a computer to identify words and phrases that signal factuality and to determine events with the said factuality, paving the way for grounding possible and counterfactual states.&lt;/p></description></item><item><title>Aspect-based Sentiment Evaluation of Chess Moves (ASSESS): an NLP-based Method for Evaluating Chess Strategies from Textbooks</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/aspect-based-sentiment-evaluation-of-chess-moves-assess-an-nlp-based-method-for-evaluating-chess-strategies-from-textbooks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/aspect-based-sentiment-evaluation-of-chess-moves-assess-an-nlp-based-method-for-evaluating-chess-strategies-from-textbooks/</guid><description>&lt;p>The chess domain is well-suited for creating an artificial intelligence (AI) system that mimics real-world challenges, including decision-making. Throughout the years, minimal attention has been paid to investigating insights derived from unstructured chess data sources. In this study, we examine the complicated relationships between multiple referenced moves in a chess-teaching textbook, and propose a novel method designed to encapsulate chess knowledge derived from move-action phrases. This study investigates the feasibility of using a modified sentiment analysis method as a means for evaluating chess moves based on text. Our proposed Aspect-Based Sentiment Analysis (ABSA) method represents an advancement in evaluating the sentiment associated with referenced chess moves. By extracting insights from move-action phrases, our approach aims to provide a more fine-grained and contextually aware {\textquoteleft}chess move&amp;rsquo;-based sentiment classification. Through empirical experiments and analysis, we evaluate the performance of our fine-tuned ABSA model, presenting results that confirm the efficiency of our approach in advancing aspect-based sentiment classification within the chess domain. This research contributes to the area of game-playing by machines and shows the practical applicability of leveraging NLP techniques to understand the context of strategic games. Keywords: Natural Language Processing, Chess, Aspect-based Sentiment Analysis (ABSA), Chess Move Evaluation.&lt;/p></description></item><item><title>Detection and labeling of bad moves for coaching go</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/detection-and-labeling-of-bad-moves-for-coaching-go/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/detection-and-labeling-of-bad-moves-for-coaching-go/</guid><description>&lt;p>The level of computer programs has now reached professional strength for many games, even for the game of Go recently. A more difficult task for computer intelligence now is to create a program able to coach human players, so that they can improve their play. In this paper, we propose a method to detect and label the bad moves of human players for the game of Go. This task is challenging because even strong human players only agree at a rate of around 50% about which moves should be considered as bad. We use supervised learning with features largely available in many Go programs, and we obtain an identification level close to the one observed between strong human players. Also, an evaluation by a professional player shows that our method is already useful for intermediate-level players.&lt;/p></description></item><item><title>Enhancing Commentary Strategies for Imperfect Information Card Games: A Study of Large Language Models in Guandan Commentary</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/enhancing-commentary-strategies-for-imperfect-information-card-games-a-study-of-large-language-models-in-guandan-commentary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/enhancing-commentary-strategies-for-imperfect-information-card-games-a-study-of-large-language-models-in-guandan-commentary/</guid><description>&lt;p>Recent advancements in large language models (LLMs) have unlocked the potential for generating high-quality game commentary. However, producing insightful and engaging commentary for complex games with incomplete information remains a significant challenge. In this paper, we introduce a novel commentary method that combine Reinforcement Learning (RL) and LLMs, tailored specifically for the Chinese card game \textit{Guandan}. Our system leverages RL to generate intricate card-playing scenarios and employs LLMs to generate corresponding commentary text, effectively emulating the strategic analysis and narrative prowess of professional commentators. The framework comprises a state commentary guide, a Theory of Mind (ToM)-based strategy analyzer, and a style retrieval module, which seamlessly collaborate to deliver detailed and context-relevant game commentary in the Chinese language environment. We empower LLMs with ToM capabilities and refine both retrieval and information filtering mechanisms. This facilitates the generation of personalized commentary content. Our experimental results showcase the substantial enhancement in performance achieved by the proposed commentary framework when applied to open-source LLMs, surpassing the performance of GPT-4 across multiple evaluation metrics.&lt;/p></description></item><item><title>Learning a game commentary generator with grounded move expressions</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-a-game-commentary-generator-with-grounded-move-expressions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-a-game-commentary-generator-with-grounded-move-expressions/</guid><description>&lt;p>This paper describes a machine learning-based approach for generating natural language comments on Shogi games. We generate comments by using a discriminative language model trained with a large amount of Shogi game records and comments made by human experts. Central to our method is accurate mapping of move expressions appearing in experts&amp;rsquo; comments to game states (i.e. positions) of Shogi, because the discriminative language model is trained with textual expressions paired with corresponding Shogi positions. We describe how such mapping can be performed by using evaluation information obtained from a Shogi program. Experimental results show that we can actually generate helpful comments for some positions.&lt;/p></description></item><item><title>Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-to-generate-move-by-move-commentary-for-chess-games-from-large-scale-social-forum-data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/learning-to-generate-move-by-move-commentary-for-chess-games-from-large-scale-social-forum-data/</guid><description>&lt;p>This paper examines the problem of generating natural language descriptions of chess games. We introduce a new large-scale chess commentary dataset and propose methods to generate commentary for individual moves in a chess game. The introduced dataset consists of more than 298K chess move-commentary pairs across 11K chess games. We highlight how this task poses unique research challenges in natural language generation: the data contain a large variety of styles of commentary and frequently depend on pragmatic context. We benchmark various baselines and propose an end-to-end trainable neural model which takes into account multiple pragmatic aspects of the game state that may be commented upon to describe a given chess move. Through a human study on predictions for a subset of the data which deals with direct move descriptions, we observe that outputs from our models are rated similar to ground truth commentary texts in terms of correctness and fluency.&lt;/p></description></item><item><title>SentiMATE: Learning to play Chess through Natural Language Processing</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/sentimate-learning-to-play-chess-through-natural-language-processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/sentimate-learning-to-play-chess-through-natural-language-processing/</guid><description>&lt;p>We present SentiMATE, a novel end-to-end Deep Learning model for Chess, employing Natural Language Processing that aims to learn an effective evaluation function assessing move quality. This function is pre-trained on the sentiment of commentary associated with the training moves and is used to guide and optimize the agent&amp;rsquo;s game-playing decision making. The contributions of this research are three-fold: we build and put forward both a classifier which extracts commentary describing the quality of Chess moves in vast commentary datasets, and a Sentiment Analysis model trained on Chess commentary to accurately predict the quality of said moves, to then use those predictions to evaluate the optimal next move of a Chess agent. Both classifiers achieve over 90 which evaluates Chess moves based on a pre-trained sentiment evaluation function. Our results exhibit strong evidence to support our initial hypothesis - &amp;ldquo;Can Natural Language Processing be used to train a novel and sample efficient evaluation function in Chess Engines?&amp;rdquo; - as we integrate our evaluation function into modern Chess engines and play against agents with traditional Chess move evaluation functions, beating both random agents and a DeepChess implementation at a level-one search depth - representing the number of moves a traditional Chess agent (employing the alpha-beta search algorithm) looks ahead in order to evaluate a given chess state.&lt;/p></description></item><item><title>Understanding Game-Playing Agents with Natural Language Annotations</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/</guid><description>&lt;p>We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.&lt;/p></description></item></channel></rss>