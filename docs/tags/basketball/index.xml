<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Basketball on Datasheet for Game Commentary Datasets</title><link>https://ZzZqr.github.io/AIGGC-datasheet/tags/basketball/</link><description>Recent content in Basketball on Datasheet for Game Commentary Datasets</description><generator>Hugo -- 0.147.2</generator><language>en-us</language><atom:link href="https://ZzZqr.github.io/AIGGC-datasheet/tags/basketball/index.xml" rel="self" type="application/rss+xml"/><item><title>A Descriptive Basketball Highlight Dataset for Automatic Commentary Generation</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-descriptive-basketball-highlight-dataset-for-automatic-commentary-generation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-descriptive-basketball-highlight-dataset-for-automatic-commentary-generation/</guid><description>&lt;p>The emergence of video captioning makes it possible to automatically generate natural language description for a given video. However, generating detailed video descriptions that incorporate domain-specific information remains an unsolved challenge, holding significant research and application value, particularly in domains such as sports commentary generation. Moreover, sports event commentary goes beyond being a mere game report, it involves entertaining, metaphorical, and emotional descriptions. To promote the field of sports commentary automatic generation, in this paper, we introduce a novel dataset, the Basketball Highlight Commentary (BH-Commentary), comprising approximately 4K basketball highlight videos with groundtruth commentaries from professional commentators. In addition, we propose an end-to-end framework as a benchmark for basketball highlight commentary generation task, in which a lightweight and effective prompt strategy is designed to enhance alignment fusion among visual and textual features. Experimental results on the BH-Commentary dataset demonstrate the validity of the dataset and the effectiveness of the proposed benchmark for sports highlight commentary generation.&lt;/p></description></item><item><title>Fine-Grained Video Captioning via Graph-based Multi-Granularity Interaction Learning</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/fine-grained-video-captioning-via-graph-based-multi-granularity-interaction-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/fine-grained-video-captioning-via-graph-based-multi-granularity-interaction-learning/</guid><description>&lt;p>Learning to generate continuous linguistic descriptions for multi-subject interactive videos in great details has particular applications in team sports auto-narrative. In contrast to traditional video caption, this task is more challenging as it requires simultaneous modeling of fine-grained individual actions, uncovering of spatio-temporal dependency structures of frequent group interactions, and then accurate mapping of these complex interaction details into long and detailed commentary. To explicitly address these challenges, we propose a novel framework &lt;italic>Graph-based Learning for Multi-Granularity Interaction Representation (GLMGIR)&lt;/italic> for fine-grained team sports auto-narrative task. A multi-granular interaction modeling module is proposed to extract among-subjectsâ€™ interactive actions in a progressive way for encoding both intra- and inter-team interactions. Based on the above multi-granular representations, a multi-granular attention module is developed to consider action/event descriptions of multiple spatio-temporal resolutions. Both modules are integrated seamlessly and work in a collaborative way to generate the final narrative. In the meantime, to facilitate reproducible research, we collect a new video dataset from &lt;italic>YouTube.com&lt;/italic> called Sports Video Narrative dataset (SVN). It is a novel direction as it contains &lt;inline-formula>&lt;tex-math notation="LaTeX">$6K$&lt;/tex-math>&lt;alternatives>&lt;a href="mml:math">mml:math&lt;/a>&lt;a href="mml:mrow">mml:mrow&lt;/a>&lt;a href="mml:mn">mml:mn&lt;/a>6&amp;lt;/mml:mn&amp;gt;&lt;a href="mml:mi">mml:mi&lt;/a>K&amp;lt;/mml:mi&amp;gt;&amp;lt;/mml:mrow&amp;gt;&amp;lt;/mml:math&amp;gt;&lt;inline-graphic xlink:href="zhuang-ieq1-2946823.gif"/>&lt;/alternatives>&lt;/inline-formula> team sports videos (i.e., NBA basketball games) with &lt;inline-formula>&lt;tex-math notation="LaTeX">$10K$&lt;/tex-math>&lt;alternatives>&lt;a href="mml:math">mml:math&lt;/a>&lt;a href="mml:mrow">mml:mrow&lt;/a>&lt;a href="mml:mn">mml:mn&lt;/a>10&amp;lt;/mml:mn&amp;gt;&lt;a href="mml:mi">mml:mi&lt;/a>K&amp;lt;/mml:mi&amp;gt;&amp;lt;/mml:mrow&amp;gt;&amp;lt;/mml:math&amp;gt;&lt;inline-graphic xlink:href="zhuang-ieq2-2946823.gif"/>&lt;/alternatives>&lt;/inline-formula> ground-truth narratives(e.g., sentences). Furthermore, as previous metrics such as METEOR (i.e., used in coarse-grained video caption task) DO NOT cope with fine-grained sports narrative task well, we hence develop a novel evaluation metric named Fine-grained Captioning Evaluation (FCE), which measures how accurate the generated linguistic description reflects fine-grained action details as well as the overall spatio-temporal interactional structure. Extensive experiments on our SVN dataset have demonstrated the effectiveness of the proposed framework for fine-grained team sports video auto-narrative.&lt;/p></description></item><item><title>GameFlow: Narrative Visualization of NBA Basketball Games</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/gameflow-narrative-visualization-of-nba-basketball-games/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/gameflow-narrative-visualization-of-nba-basketball-games/</guid><description>&lt;p>Although basketball games have received broad attention, the forms of game reports and webcast are purely content-based cross-media: texts, videos, snapshots, and performance figures. Analytical narrations of games that seek to compose a complete game from heterogeneous datasets are challenging for general media producers because such a composition is time-consuming and heavily depends on domain experts. In particular, an appropriate analytical commentary of basketball games requires two factors, namely, rich context and domain knowledge, which includes game events, player locations, player profiles, and team profiles, among others. This type of analytical commentary elicits a timely and effective basketball game data visualization made up of different sources of media. Existing visualizations of basketball games mainly profile a particular aspect of the game. Therefore, this paper presents an expressive visualization scheme that comprehensively illustrates NBA games with three levels of details: a season level, a game level, and a session level. We reorganize a basketball game as a sequence of sessions to depict the game states and heated confrontations. We design and implement a live system that integrates multimedia NBA datasets: play-by-play text data, box score data, game video data, and action area data. We demonstrate the effectiveness of this scheme with case studies and user feedbacks.&lt;/p></description></item></channel></rss>