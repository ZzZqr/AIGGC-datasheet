<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Go on Datasheet for Game Commentary Datasets</title><link>https://ZzZqr.github.io/AIGGC-datasheet/tags/go/</link><description>Recent content in Go on Datasheet for Game Commentary Datasets</description><generator>Hugo -- 0.147.2</generator><language>en-us</language><atom:link href="https://ZzZqr.github.io/AIGGC-datasheet/tags/go/index.xml" rel="self" type="application/rss+xml"/><item><title>Detection and labeling of bad moves for coaching go</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/detection-and-labeling-of-bad-moves-for-coaching-go/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/detection-and-labeling-of-bad-moves-for-coaching-go/</guid><description>&lt;p>The level of computer programs has now reached professional strength for many games, even for the game of Go recently. A more difficult task for computer intelligence now is to create a program able to coach human players, so that they can improve their play. In this paper, we propose a method to detect and label the bad moves of human players for the game of Go. This task is challenging because even strong human players only agree at a rate of around 50% about which moves should be considered as bad. We use supervised learning with features largely available in many Go programs, and we obtain an identification level close to the one observed between strong human players. Also, an evaluation by a professional player shows that our method is already useful for intermediate-level players.&lt;/p></description></item><item><title>Understanding Game-Playing Agents with Natural Language Annotations</title><link>https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/</guid><description>&lt;p>We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.&lt;/p></description></item></channel></rss>