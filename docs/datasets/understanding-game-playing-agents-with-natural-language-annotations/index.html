<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Understanding Game-Playing Agents with Natural Language Annotations | Datasheet for Game Commentary Datasets</title>
<meta name=keywords content="Board,Go"><meta name=description content="We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations."><meta name=author content><link rel=canonical href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/><link crossorigin=anonymous href=/AIGGC-datasheet/assets/css/stylesheet.6e3cae23ffdb771f23d63cb0f916b137936e5c06b0eed3ec4bc79a2b0809b644.css integrity rel="preload stylesheet" as=style><link rel=icon href=https://ZzZqr.github.io/AIGGC-datasheet/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ZzZqr.github.io/AIGGC-datasheet/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ZzZqr.github.io/AIGGC-datasheet/favicon-32x32.png><link rel=apple-touch-icon href=https://ZzZqr.github.io/AIGGC-datasheet/apple-touch-icon.png><link rel=mask-icon href=https://ZzZqr.github.io/AIGGC-datasheet/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/"><meta property="og:site_name" content="Datasheet for Game Commentary Datasets"><meta property="og:title" content="Understanding Game-Playing Agents with Natural Language Annotations"><meta property="og:description" content="We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="datasets"><meta property="article:tag" content="Board"><meta property="article:tag" content="Go"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding Game-Playing Agents with Natural Language Annotations"><meta name=twitter:description content="We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Game Commentary Datasets","item":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/"},{"@type":"ListItem","position":2,"name":"Understanding Game-Playing Agents with Natural Language Annotations","item":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Understanding Game-Playing Agents with Natural Language Annotations","name":"Understanding Game-Playing Agents with Natural Language Annotations","description":"We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.\n","keywords":["Board","Go"],"articleBody":"We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.\nDownload Paper\rDownload BibTeX\r","wordCount":"121","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/understanding-game-playing-agents-with-natural-language-annotations/"},"publisher":{"@type":"Organization","name":"Datasheet for Game Commentary Datasets","logo":{"@type":"ImageObject","url":"https://ZzZqr.github.io/AIGGC-datasheet/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://ZzZqr.github.io/AIGGC-datasheet/ accesskey=h title="Datasheet for Game Commentary Datasets (Alt + H)">Datasheet for Game Commentary Datasets</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/ title=Datasets><span>Datasets</span></a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/datasheet/ title=Datasheet><span>Datasheet</span></a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Understanding Game-Playing Agents with Natural Language Annotations</h1><div class=post-meta></div></header><div class=post-content><p>We present a new dataset containing 10K human-annotated games of Go and show how these natural language annotations can be used as a tool for model interpretability. Given a board state and its associated comment, our approach uses linear probing to predict mentions of domain-specific terms (e.g., ko, atari) from the intermediate state representations of game-playing agents like AlphaGo Zero. We find these game concepts are nontrivially encoded in two distinct policy networks, one trained via imitation learning and another trained via reinforcement learning. Furthermore, mentions of domain-specific terms are most easily predicted from the later layers of both models, suggesting that these policy networks encode high-level abstractions similar to those used in the natural language annotations.</p><div style=margin-top:1rem;padding:1rem;display:inline-block><a href=https://aclanthology.org/2022.acl-short.90/ target=_blank style="background-color:#0d9bdc;color:#fff;padding:10px 16px;margin-right:8px;text-decoration:none;border-radius:4px;font-weight:700">Download Paper
</a><a href=bib/understanding-game-playing-agents-with-natural-language-annotations.bib download style="background-color:#f0a500;color:#fff;padding:10px 16px;text-decoration:none;border-radius:4px;font-weight:700">Download BibTeX</a></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/tags/board/>Board</a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/tags/go/>Go</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ZzZqr.github.io/AIGGC-datasheet/>Datasheet for Game Commentary Datasets</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>