<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Hybrid Deep Learning Model for Automated Cricket Commentary Generation | Datasheet for Game Commentary Datasets</title>
<meta name=keywords content="Sports,Cricket"><meta name=description content="The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model."><meta name=author content><link rel=canonical href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/><link crossorigin=anonymous href=/AIGGC-datasheet/assets/css/stylesheet.6e3cae23ffdb771f23d63cb0f916b137936e5c06b0eed3ec4bc79a2b0809b644.css integrity rel="preload stylesheet" as=style><link rel=icon href=https://ZzZqr.github.io/AIGGC-datasheet/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ZzZqr.github.io/AIGGC-datasheet/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ZzZqr.github.io/AIGGC-datasheet/favicon-32x32.png><link rel=apple-touch-icon href=https://ZzZqr.github.io/AIGGC-datasheet/apple-touch-icon.png><link rel=mask-icon href=https://ZzZqr.github.io/AIGGC-datasheet/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:url" content="https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/"><meta property="og:site_name" content="Datasheet for Game Commentary Datasets"><meta property="og:title" content="A Hybrid Deep Learning Model for Automated Cricket Commentary Generation"><meta property="og:description" content="The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="datasets"><meta property="article:tag" content="Sports"><meta property="article:tag" content="Cricket"><meta name=twitter:card content="summary"><meta name=twitter:title content="A Hybrid Deep Learning Model for Automated Cricket Commentary Generation"><meta name=twitter:description content="The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Datasets","item":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/"},{"@type":"ListItem","position":2,"name":"A Hybrid Deep Learning Model for Automated Cricket Commentary Generation","item":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Hybrid Deep Learning Model for Automated Cricket Commentary Generation","name":"A Hybrid Deep Learning Model for Automated Cricket Commentary Generation","description":"The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model.\n","keywords":["Sports","Cricket"],"articleBody":"The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model.\nDownload Paper\rDownload BibTeX\r","wordCount":"149","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://ZzZqr.github.io/AIGGC-datasheet/datasets/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation/"},"publisher":{"@type":"Organization","name":"Datasheet for Game Commentary Datasets","logo":{"@type":"ImageObject","url":"https://ZzZqr.github.io/AIGGC-datasheet/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://ZzZqr.github.io/AIGGC-datasheet/ accesskey=h title="Datasheet for Game Commentary Datasets (Alt + H)">Datasheet for Game Commentary Datasets</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/datasets/ title=Datasets><span>Datasets</span></a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/datasheet/ title=Datasheet><span>Datasheet</span></a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">A Hybrid Deep Learning Model for Automated Cricket Commentary Generation</h1><div class=post-meta></div></header><div class=post-content><p>The paper proposes an innovative method for generating cricket commentary. A hybrid model is proposed that combines three types of neural networks: Convolutional Neural Networks (CNN) for image processing, Long Short-Term Memory (LSTM) networks for sequential text generation, and Graph Convolutional Networks (GCN) for semantic understanding. By integrating these components, the model can generate ball-by-ball commentary that is coherent and contextaware. The model works by processing video frames from a cricket match using CNN. The resulting feature maps are used to retain essential visual information. Fully connected layers transform the features to a format suitable for input into the LSTM. The LSTM generates one word at a time, considering the temporal dependencies inherent in ball-by-ball events. To enhance the semantic understanding between the generated captions, the GCN is used. Evaluation metrics like BLEU, METEOR, and ROUGE are used to assess the proficiency of the model.</p><div style=margin-top:1rem;padding:1rem;display:inline-block><a href=https://doi.org/10.1109/ICCCMLA63077.2024.10871604 target=_blank style="background-color:#0d9bdc;color:#fff;padding:10px 16px;margin-right:8px;text-decoration:none;border-radius:4px;font-weight:700">Download Paper
</a><a href=bib/a-hybrid-deep-learning-model-for-automated-cricket-commentary-generation.bib download style="background-color:#f0a500;color:#fff;padding:10px 16px;text-decoration:none;border-radius:4px;font-weight:700">Download BibTeX</a></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/tags/sports/>Sports</a></li><li><a href=https://ZzZqr.github.io/AIGGC-datasheet/tags/cricket/>Cricket</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ZzZqr.github.io/AIGGC-datasheet/>Datasheet for Game Commentary Datasets</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>